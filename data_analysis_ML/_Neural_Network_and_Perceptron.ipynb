{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOSEQf7MKrXQ2z/22ht5AeN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 11.1 인간 뇌의 비밀\n","* 뇌가 가지는 구조의 개략적인 특징을 이해하고 있다. 그것은 바로 뉴런이라는 신경세포가 다른 신경세포와 연결되어 있고, 화학적 신호를 주고받는다는 사실이다.\n","* 인공적인 신경세포(artificial neuron)를 흉내 내는 프로그램을 컴퓨터 과학자들은 퍼셉트론(perceptron)이라고 한다.\n","\n","# 11.2 단순한 퍼셉트론의 구조를 살펴보자\n","* 출력 노드로 전달되는 부분은 두 개의 기능으로 구분할 수 있다.\n","* 먼저 전달되는 입력 신호를 연결 강도와 곱한 후 모두 합하는 부분이다. 이렇게 합산된 신호가 다음 계층으로 신호를 보낼 것인지 말 것인지는 활성화 함수(activation function)에 의해 결정된다.\n","* 만약 이 노드가 최종 노드라고 하면 이 결과가 옳은지 답이 되는 레이블과 비교하여 오차를 구할 수 있다.\n","* 활성화 함수는 해당 값의 범위를 제한하거나 변형시키는데, 출력 노드에 모인 신호를 다음 층으로 내어보낼 때 얼마나 강하게 보낼지를 결정하는 함수이다.\n","* 전통적으로 많이 사용되던 활성화 함수는 시그모이드(sigmoid) 함수이다. 이 함수는 입력에 해당하는 x값이 증가함에 따라 S자 모양으로 y축 방향의 값이 증가하는 형태를 띠고 있는 함수이다. 하지만 이로는 깊은 층을 가진 신경망을 학습시키기가 어렵다는 것이 드러났다.\n","* 따라서 최근에는 ReLU라고 불리는 정류 선형 유닛(rectified linear unit)함수가 좋은 결과를 내는 것으로 알려져 있다.\n","* 신경망이 동작을 변경하는 방법은 연결 강도를 조정하는 것인데 출력을 목표치와 비교하여 오차를 계산하고 이 오차를 줄이는 방향으로 연결 강도를 변경한다. 이때 이 연결 강도를 모델의 파라미터(parameter)라고 부른다.\n","* 오차를 줄이는 방향으로 모델의 파라미터를 조정하는 일을 최적화(optimization)이라고 부르는데 이것이 바로 학습이다.\n","* 이러한 파라미터를 찾기 위한 학습 과정을 조절하는 변수들을 하이퍼파라미터라고 한다.\n","\n","# 11.3 신경망을 만들기 위한 간단한 행렬 표현법\n","* 다음과 같이 입력값이 있고 이에 대한 가중치를 곱한 후 이 가중치의 가중합을 구하는 방법을 표현하기 위해서 여러 가지 방법이 사용될 수 있다."],"metadata":{"id":"jIjtIcNO41YD"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EuoGemiX4vA0","executionInfo":{"status":"ok","timestamp":1738459698344,"user_tz":-540,"elapsed":297,"user":{"displayName":"Dohyun Kim","userId":"02569473351456409197"}},"outputId":"640517b2-b810-46d2-e4ca-ebf406c6e86c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.5, 1.2])"]},"metadata":{},"execution_count":1}],"source":["import numpy as np\n","X = np.array([1,2])       # 입력 벡터 X\n","W = np.array([0.5, 0.6])  # 가중치 벡터 W\n","X * W"]},{"cell_type":"code","source":["np.sum(X*W), np.dot(X, W) # sum function, dot function to measure weighted sum"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueTHOZyhRb0v","executionInfo":{"status":"ok","timestamp":1738459723309,"user_tz":-540,"elapsed":271,"user":{"displayName":"Dohyun Kim","userId":"02569473351456409197"}},"outputId":"383567b6-7db1-4382-d75a-e612d057c1d0"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.7, 1.7)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["X = np.array([1,2])\n","W = np.array([[1,2,3], [4,5,6]])\n","A = np.dot(X,W)\n","print('A =', A)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TAQC-L4nR8ef","executionInfo":{"status":"ok","timestamp":1738459895083,"user_tz":-540,"elapsed":249,"user":{"displayName":"Dohyun Kim","userId":"02569473351456409197"}},"outputId":"100aa1eb-26aa-4895-98da-87f4118b5677"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["A = [ 9 12 15]\n"]}]},{"cell_type":"markdown","source":["# 11.4 AND와 OR 회로를 퍼셉트론으로 만들자\n","* 컴퓨터는 기본적인 회로인 AND, OR, NOT 회로를 가지고 있으며, 이러한 것들을 조합하여 복잡한 연산을 수행한다. 이러한 회로를 논리 회로(logical circuit)라고 한다.\n","* 일반적인 컴퓨터 프로그래밍 언어는 참값으로 1, 거짓 값으로 0을 사용하지만, 이 회로의 경우 신호를 크게 분리하기 위해 참은 1, 거짓은 -1값을 사용할 것이다.\n","* 퍼셉트론 모델 perceptron()함수는 아래와 같이 두 개의 입력에 대해 w 벡터가 곱해지고 편향 b가 더해진 결과값 tmp가 활성화 함수를 통과하도록 만들면 된다.\n","* 활성화 함수는 activation()이라는 이름의 함수로 구현되었다. 이 함수는 입력이 0보다 크면1, 그렇지 않으면 -1을 반환하는 함수인데, 이런 모양의 함수를 계단 함수(step function)라고 한다."],"metadata":{"id":"k_orRHf2SPSH"}},{"cell_type":"code","source":["import numpy as np\n","\n","def activation(s):\n","  if s > 0:\n","    return 1\n","  else:\n","    return -1\n","\n","def perceptron(x1, x2):\n","  x = np.array([x1, x2])\n","  tmp = np.sum(W*X)+b\n","  return activation(tmp)"],"metadata":{"id":"CLF7iJLnTAxN","executionInfo":{"status":"ok","timestamp":1738460325871,"user_tz":-540,"elapsed":247,"user":{"displayName":"Dohyun Kim","userId":"02569473351456409197"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["* 이제 다음과 같이 W를 [0.5,0.5] 벡터로 하고 b를 -0.7이라는 값으로 초기화한 다음, 이 값을 이용하여 출력을 살펴보자\n","\n"],"metadata":{"id":"9_Vpfs7rRl4p"}},{"cell_type":"code","source":["print('---AND circuit implemented by perceptron---')\n","W  = np.array([0.5,0.5])\n","b = -0.7\n","for x1, x2 in [(-1,-1), (-1,1), (1, -1), (1,1)]:\n","  y = perceptron(x1, x2)\n","  print('{:3d} {:3d} : {:3d}'.format(x1,x2, y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbJXGN01ThdD","executionInfo":{"status":"ok","timestamp":1738460360504,"user_tz":-540,"elapsed":259,"user":{"displayName":"Dohyun Kim","userId":"02569473351456409197"}},"outputId":"c8b2af25-ff80-4ced-95e2-bc7c8268a75c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["---AND circuit implemented by perceptron---\n"," -1  -1 :   1\n"," -1   1 :   1\n","  1  -1 :   1\n","  1   1 :   1\n"]}]},{"cell_type":"markdown","source":["# 11.5 퍼셉트로을 학습시키자\n","* 연결의 가중치, 즉 연결 강도를 변경할 수 있다는 것은 신경세포의 연결망을 학습시킬 수 있다는 것이다. 헵의 학습 법칙은 신경세포에 가해지는 입력과 출력에 따라 새로운 가중치를 다음과 같이 바꾸어 나간다는 것이다.\n","\n","# 11.6 퍼센트론을 학습시키는 알고리즘을 구현하자\n"],"metadata":{"id":"qhjpHztQUSbl"}},{"cell_type":"code","source":["import numpy as np\n","\n","def activation(s):\n","  if s>0: return 1\n","  else: return -1\n","\n","def out(x):\n","  return activation(W.dot(x)) # W.dot(x): multiply every element in W and x and sum them up return."],"metadata":{"id":"411CujFbU2YM","executionInfo":{"status":"ok","timestamp":1738460693680,"user_tz":-540,"elapsed":327,"user":{"displayName":"Dohyun Kim","userId":"02569473351456409197"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# 11.8 다층 퍼셉트론으로 XOR 연산을 하자\n","비선형 함수를 만드는 방법 중의 하나로 입력층과 출력 사이에 신호를 중계하는 노드를 두는 방법이 있을 수 있다.\n","* 입력과 출력 사이에 존재하는 이런 중간 노드들을 은닉노드(hidden node)라고 하며 이들의 계층을 은닉층(hidden layer)이라고 부른다.\n","\n","# 11.9 오차 역전파를 개략적으로 살펴보자\n","* 앞서 다룬 다층 퍼센트론은 신경망(neural network)라고 불린다.\n","1. 순방향 패스를 따라서 출력값이 계산된다.\n","2. 그리고, 이 출력값이 목표값과 얼마만큼의 차이가 나는지를 계산한다.\n","3. 다층 퍼셉트론의 역방향 패스를 따라서 가중치를 갱신한다.\n","* 이러한 방법으로 다중 퍼셉트론의 가중치를 갱신시키며 최적의 가중치를 찾은 알고리즘을 오차 역전파(error back propagation) 알고리즘이라고 한다."],"metadata":{"id":"9W1Xi_snWKJh"}}]}